---
title: "Dissertation"
format: pdf
editor: visual
---

```{r}
library(ggplot2)
library(tidyverse)
library(stringr)
library(sf)
library(leaflet)
library(fs)
```

```{r}
base_dir <- "Weather Data/Automated_daily"
download_dir <- "C:/Users/Admin/Downloads"
```

```{r}
station_details = read_csv("scraping/downloaded_data_daily_log.csv")

zip_files <- list.files(download_dir, pattern = "\\.zip$", full.names = TRUE)
zip_info <- file.info(zip_files)
ordered_zips <- zip_files[order(zip_info$mtime)]  # Oldest first

station_details$current_path = ordered_zips
```

```{r}
#!!!!!!!!RUN ONLY ONCE. FIRST TIME ONLY!!!!!!!
counties = unique(station_details$County)
count = 1

for(c in counties){
  county_path <- file.path(base_dir, c)
  dir.create(county_path, recursive = TRUE, showWarnings = FALSE)

  stations = station_details |>
    filter(County == c) |>
    dplyr::select(Station)
  
  for(station in stations$Station){
    station_path <- file.path(county_path, station)
    dir.create(station_path, showWarnings = FALSE)
    file_move(station_details$current_path[count], station_path)
    count = count + 1
  }
}
```

```{r}
#!!!!!!!!!!!!RUN ONLY ONCE!!!!!!!!!!!!!!!!!
zip_files <- list.files(base_dir, pattern = "\\.zip$", full.names = TRUE, recursive = TRUE)

walk(zip_files, function(zip_path) {
  unzip(zipfile = zip_path, exdir = dirname(zip_path))
  file.remove(zip_path)
})
```

```{r}
# Function to read and process one file
process_file <- function(file_path) {
  
  # Read the first few lines
  lines <- readLines(file_path, n = 30)
  
  # Extract station name (adjust indexing if needed)
  station_line <- lines[1]
  station_name <- str_trim(str_split(station_line, ":")[[1]][2])
  
  latlog_line <- lines[3]
  latitude <- as.numeric(str_split(str_trim(str_split(latlog_line,",")[[1]][1]),":")[[1]][2])
  longitude <- as.numeric(str_split(str_trim(str_split(latlog_line,",")[[1]][2]),":")[[1]][2])
  
  # Find where the header starts
  header_row <- which(str_detect(lines, "date"))[2]
  
  # Read the actual data
  df <- read_csv(file_path, skip = header_row - 1) |>
    mutate(AreaOfResidence = station_name, Latitude = latitude, Longitude = longitude)
  
  if(nrow(df) == 0) {
    return(NULL)
  }
  
  return(df)
}

all_files <- list.files(base_dir, pattern = "\\.csv$", full.names = TRUE, recursive = TRUE)
# Use purrr::map to apply the function to all files
final_weather_data <- map_dfr(all_files, process_file)

# Save if needed
write_csv(final_weather_data, "Weather Data/weather_data_daily_complete.csv")
```

Text files processing

```{r}
text_files_dir = "Weather Data/Text files"
text_files = list.files(text_files_dir, pattern = "\\.txt$", full.names = TRUE, recursive = TRUE)

station_details = read_delim(text_files[3], delim = ",", skip = 23, trim_ws = TRUE)
```

```{r}
dms_colon_to_dd <- function(dms_str) {
  parts <- strsplit(dms_str, ":")[[1]]
  deg <- as.numeric(parts[1])
  min <- as.numeric(parts[2])
  sec <- as.numeric(parts[3])
  
  sign <- ifelse(deg < 0, -1, 1)
  dd <- abs(deg) + min / 60 + sec / 3600
  return(sign * dd)
}

station_details = station_details |>
  rowwise() |>
  mutate(lat_dd = dms_colon_to_dd(LAT),
         lon_dd = dms_colon_to_dd(LON),
         ) |>
  ungroup() |>
  dplyr::select(STAID, SOUNAME, lat_dd, lon_dd) |>
  rename(ID = STAID, NAME = SOUNAME, Latitude = lat_dd, Longitude = lon_dd)
```

```{r}
temperature_data <- map_dfr(
  text_files[4:length(text_files)],
  ~ read_delim(.x, delim = ",", skip = 21, trim_ws = TRUE)
)
```

```{r}
final_temperature_data = temperature_data |> 
  filter(Q_TG != 9) |> 
  mutate(DATE = ymd(DATE), 
         day = day(DATE), 
         month = month(DATE), 
         year = year(DATE)
         ) |>
  filter(year > 2000) |>
  rename(ID = STAID,`Mean Temperature` = TG) |>
  left_join(station_details, by = "ID") |>
  dplyr::select(ID, NAME, Latitude, Longitude, day, month, year, `Mean Temperature`)
```

```{r}
write_csv(final_temperature_data, "Weather Data/temperature_data.csv")
```
